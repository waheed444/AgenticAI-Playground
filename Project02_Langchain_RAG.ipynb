{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzCp35SavO6dpom9iJCGzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waheed444/AgenticAI-Playground/blob/main/Project02_Langchain_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up the Environment & Install Prerequisites"
      ],
      "metadata": {
        "id": "u0hYYdOBbOfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q --upgrade google-generativeai langchain langchain-community langchain-google-genai chromadb pypdf\n"
      ],
      "metadata": {
        "id": "FJjhol8OWKtV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the output in  Proper Formate"
      ],
      "metadata": {
        "id": "KvfemeSDzFmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "xneaxYvGx-TI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import **google.generativeai** & Configure the **API Key**"
      ],
      "metadata": {
        "id": "hVFySiHVb1mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "iNexSDVoX4Bf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import **Libraries** to build QnA System using **PDF Data** Integration"
      ],
      "metadata": {
        "id": "4VF2zd-hcSGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# restart python kernal if issues with langchain import."
      ],
      "metadata": {
        "id": "61slydEBYQvp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import **ChatGoogleGenerativeAI**"
      ],
      "metadata": {
        "id": "uiNKLrfH0tUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "ovwlpefMYjZu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure **gimini-pro** model with custom parameters"
      ],
      "metadata": {
        "id": "hKI81AUscmTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0.6,\n",
        "    convert_system_message_to_human=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "t3Cc55WvYnu2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check file Existence using **pathlib** library"
      ],
      "metadata": {
        "id": "fh9JZw9_c8Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "file_path = Path(\"/content/RAG_File.pdf\")\n",
        "if file_path.exists():\n",
        "    print(\"File exists and is ready for processing.\")\n",
        "else:\n",
        "    print(\"File does not exist. Please upload it.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LDRScHMYuKX",
        "outputId": "b6ec8fa7-fce1-4321-9eb0-074f1e99a6e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists and is ready for processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading & Splitting PDF Content Using **PyPDFLoader** library"
      ],
      "metadata": {
        "id": "7vMd4-UGdKZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_loader = PyPDFLoader(\"/content/RAG_File.pdf\")\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[3].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDCyrPEfZZVa",
        "outputId": "40865eb0-0c81-4a03-f495-684d554e329a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "technologies.Useopensourcelibraries,likeLangchain,CrewAI,andLangGraphtoautomaterepeatable,multi-steptasksandautomatebusinessprocessesthataretypicallydonebyagroupofpeople.\n",
            "Certifications:\n",
            "■ MicrosoftCertified:AzureAIEngineerAssociate■ CertifiedcrewAIEngineer\n",
            "LearningRepo:https://github.com/panaversity/learn-prompt-eng-gpts-ai-agents\n",
            "● Quarter3:CloudNativeAIPoweredMicroservicesDesign,Development,andDeployment:\n",
            "BuildscalableAIPoweredAPIsusingFastAPI,Postgres,Kafka,Kong,GenAIAPIslikeOpenAIChatCompletionAPIs,AssistantAPIs,LangChainandOpenSourceAILLMs,developthemusingContainersandDevContainers,anddeploythemusingDockerComposelocallyandKubernetesPoweredServerlessContainerServicesonthecloud.\n",
            "WewillalsolearntointegratedesignthinkingandBehavior-DrivenDevelopment(BDD)indevelopingAIsystems.WewilllearntocreateAIsolutionsthataredeeplyalignedwithuserneedsandexpectations.Designthinkingensuresathoroughunderstandingoftheuserandproblemspace,whileBDDprovidesastructuredapproachtodefiningandvalidatingthedesiredbehavioursoftheAIsystem.Together,thesemethodologiesleadtothedevelopmentofAIsolutionsthatarenotonlytechnicallyrobustbutalsohighlyuser-centricandeffectiveinsolvingreal-worldproblems.\n",
            "○ Certifications:■ PostgreSQL13AssociateCertification■ ConfluentCertifiedDeveloperforApacheKafka(CCDAK)■ DesignThinkingProfessionalCertificate(DTPC)■ TestandBehaviorDrivenDevelopment(TDD/BDD)\n",
            "LearningRepo:\n",
            "https://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Text into Chunks for Embedding using **GoogleGenerativeAIEmbeddings**"
      ],
      "metadata": {
        "id": "DBp25UiJdWM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "JTiFXg_iZ5c9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "texts = text_splitter.split_text(context)"
      ],
      "metadata": {
        "id": "knsk5_P1Z7pq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "BmVcnw1GZ-LP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vector Indexing** to make a Retrieval-Based QnA System  "
      ],
      "metadata": {
        "id": "_jOL7AO7d-5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "waGtbc8kaAmf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask the Question and Displaying Output!"
      ],
      "metadata": {
        "id": "eVTgVIXVePZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the main topics discussed in this file?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]\n",
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "AKy2Gf1kaHZY",
        "outputId": "61bc256a-466f-4065-cb56-1a60c94d33fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This file discusses the following topics:\n- Cloud Native Applied Generative AI Engineering (GenEng)\n- FastAI and PyTorch for Fine-tuning Open-Source Large Language Models (LLMs)\n- Developing an LLM like ChatGPT4 or Google Gemini\n- Business Considerations for LLM Development\n- Custom Generative Pre-trained Transformers (GPTs)\n- Actions in GPTs\n- AI Agents and their Differences from Custom GPTs\n- Data Preparation for Fine-tuning MetaLLaMA3 with PyTorch\n- Fine-tuning MetaLLaMA3 with PyTorch\n- Utilizing FastAI for NLP Tasks in Fine-tuning MetaLLaMA3\n- Cloud-Native Training and Deployment for Fine-tuned Models\n- Exporting Models for Inference and Building Robust Inference Pipelines\n- Capstone Project for Fine-tuning and Deploying MetaLLaMA3\n- Physical AI and Humanoid Robotics Development\n- Cloud Native Microservices Deployment and Distributed System Design\n- Front-end Web GUI Development using Next.js and TypeScript\n- FAQs and Detailed Answers\n- Docker, Kubernetes, and Terraform Technologies for API Development\n- API-as-a-Product Model\n- Benefits of Docker Containers for Development, Testing, and Deployment\n- Advantages of Open Docker, Kubernetes, and Terraform Technologies\n- Advantages of Using AWS, Azure, or Google Cloud Technologies\n- Reasons for Not Learning to Build LLMs in the Program"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}